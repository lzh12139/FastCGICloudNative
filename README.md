## FastCGICloudNative
FastCGI 上云尝试



***初步考虑分成几步***

- [ ] 本地 cgi demo 环境构建，编写
- [ ] fcgi docker 构建，编译环境和运行环境
- [ ] 云上环境搭建（买个服务器）
- [ ] go 编写一个 center ，接收所有 CGI 请求并转发到对应的服务，应用 HPA 
- [ ] 移植到云上，使用云上监控（主要是 HPA）



### 部署形式 

1. 无状态

   CGI 本来就应该是无状态的服务，但是这样子部署的话，对于请求的转发需要使用轮询的方式。

   但是这会引出一个新的问题：

   >  例如某一个 pod （或者说某一个 node ）出现某些故障，所有请求全部超时，此时轮询方式会导致同样还是会有请求落到这个 pod 上

2. 有状态

   center 维护好每个 CGI 的请求量，根据空余量来转发请求。如果出现上面的问题，可以执行熔断。

   问题：

   > 1. 本应该是无状态的服务，用有状态的形式来部署，有点奇怪
   > 2. 维护请求量要注意多线程（协程），效率问题



### 一些细节及讨论

1. 对于每个 pod 内的 CGI 进程数，考虑设为一个不为 1 的值

   - 为 1 并没有什么好处，Apache 的性能足够高效
   - 不为 1 可以减少 pod 的数量，减少资源的消耗（sidecar 的占用）
   - 该值可以考虑在 docker 编译时设定

2. 访问 center 的方式：http

   因为想要尽量减少请求侧和后台侧的代码修改，所以两端都是 http 的

   对于中间侧，也只能使用 http 了

   ```mermaid
   graph LR;
   	front-->|http|CGI;
   ```

   ```mermaid
   graph LR;
   	front-->|http|center;
   	center-->|http,无法GRPC|CGI;
   ```

3. 请求突增

   需要试验一下，`HPA 的响应速度` 或 `pod 的创建速度` 可能会跟不上，导致短时间内请求大量失败

4. 自定义 HPA

   不一定能应用上 `自定义HPA` ，内网的该模块被占用了（待确认）

   先尝试自定义 HPA

